localrules: all

import sys, pandas as pd, os
from datetime import date
sys.path.insert(0, '/mnt/home/jevgen01/nmrl/bact_analysis/Ardetype/subscripts/')
from ardetype_utilities import read_json_dict, find_in_nested_dict

sip_wild = config['work_dir']+'{sample_id_pattern}_R[1,2]_001.fastq.gz'
sample_sheet = pd.read_csv(f"{config['output_directory']}sample_sheet.csv")
date = date.today().strftime("%Y-%m-%d")

rule all:
    input:
        config['shape_target_files']
    output:
        config['output_directory']+f'{date}_ardetype_report.csv'
    run:
        aggr_dict = {}
        for path in config['shape_target_files']: 
            df = pd.read_csv(path)#read each file
            if df['sample_id'][0] in aggr_dict: #if sample included before
                aggr_dict[df['sample_id'][0]] = aggr_dict[df['sample_id'][0]].join(df.loc[ : ,df.columns != "sample_id"]) #add all columns except for sample_id
            else:
                aggr_dict[df['sample_id'][0]] = df #add all columns
        report = pd.concat(aggr_dict.values()) #combile all dataframes as rows into single report (one row for each sample_id)
        report = report[[ #reorder columns
            "sample_id",
            "total_reads_bf",
            "total_reads_af",
            "q30_rbf",
            "q30_raf",
            "r1_mean_len_bf",
            "r2_mean_len_bf",
            "r1_mean_len_af",
            "r2_mean_len_af",
            "gc_bf",
            "gc_af",
            "contig_count",
            "N50",
            "assembly_length",
            "gc_contigs",
            "MLST7_ST",
            "species",
            "species_contig_%"
        ]]
        report.to_csv(output[0], header=True, index=False) #save as csv


rule extract_fastp:
    input:
        config['work_dir']+'{sample_id_pattern}.fastp.json'
    output:
        temp(config['output_directory']+'{sample_id_pattern}_fastp_std.csv')
    run:
        report = read_json_dict(input[0])
        data_dict = {
            'total_reads_bf':['summary','before_filtering','total_reads'],
            'total_reads_af':['summary','after_filtering','total_reads'],
            'q30_rbf':['summary','before_filtering','q30_rate'],
            'q30_raf':['summary','after_filtering','q30_rate'],
            'r1_mean_len_bf':['summary','before_filtering','read1_mean_length'],
            'r2_mean_len_bf':['summary','before_filtering','read2_mean_length'],
            'r1_mean_len_af':['summary','after_filtering','read1_mean_length'],
            'r2_mean_len_af':['summary','after_filtering','read2_mean_length'],
            'gc_bf':['summary','before_filtering','gc_content'],
            'gc_af':['summary','after_filtering','gc_content']
        }
        for key in data_dict: data_dict[key] = [find_in_nested_dict(report, data_dict[key])]
        data_dict['sample_id'] = wildcards.sample_id_pattern
        df = pd.DataFrame.from_dict(data_dict)
        df.to_csv(output[0], header=True, index=False)

rule extract_kraken2:
    input:
        config['work_dir']+'{sample_id_pattern}_kraken2_contigs_report.txt'
    output:
        temp(config['output_directory']+'{sample_id_pattern}_kraken2_contigs_report_std.csv')
    run:
        df = pd.read_table(input[0], header=None)[[0,3,5]]
        df.columns = ['species_contig_%','taxid','species']
        df = df[df['taxid'] == "S"].reset_index(drop=True).sort_values(by=['species_contig_%'], ascending=False).head(2)
        df['sample_id'] = [wildcards.sample_id_pattern]
        df['species'] = [df['species'][0].strip()]
        df.to_csv(output[0],header=True, index=False)

rule extract_mlst:
    input:
        config['work_dir']+'{sample_id_pattern}_mlst_output.csv'
    output:
        temp(config['output_directory']+'{sample_id_pattern}_mlst_output_std.csv')
    run:
        try:
            df = pd.read_csv(input[0], header=None)[[0,2]]
            df.columns = ['sample_id','MLST7_ST']
            df['sample_id'] = df['sample_id'].apply(lambda x: os.path.basename(x).replace("_contigs.fasta", ""))
            df.to_csv(output[0],header=True, index=False)
        except EmptyDataError as e:
            df = pd.DataFrame.from_dict({'sample_id':wildcards.sample_id_pattern, 'MLST7_ST':None})
            df.to_csv(output[0],header=True, index=False)

rule extract_quast:
    input:
        config['output_directory']+'{sample_id_pattern}_quast/transposed_report.tsv'
    output:
        temp(config['output_directory']+'{sample_id_pattern}_quast_std.csv')
    run:
        report = pd.read_csv(input[0], sep="\t")
        data_dict = {
            "contig_count":[report["# contigs"][0]],
            "N50":[report["N50"][0]],
            "assembly_length":[report["Total length"][0]],
            "gc_contigs":[report["GC (%)"][0]],
            "sample_id":wildcards.sample_id_pattern
        }
        df = pd.DataFrame.from_dict(data_dict)
        df.to_csv(output[0], header=True, index=False)

# rule run_multiqc:
#     input:
#         multiqc_sif = config['multiqc_sif']
#     output:
#         config['output_directory']+'multiqc_report.html'
#     shell:
#         '''
#         singularity run {input.multiqc_sif} multiqc {config[output_directory]} --interactive
#         '''

# rule extract_agrvate_saureus:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_agrvate_summary.tab'
#     output:
#         config['output_directory']+'{sample_id_pattern}_agrvate_summary_std.csv'
#     run:
#         report = pd.read_csv(input[0], sep="\t")
        

# rule extract_emmtyper_spyogenes:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_emmtyper.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_emmtyper_std.csv'
#     run:
#         report = pd.read_csv(input[0], sep="\t")


# rule extract_hicap_hinfluenzae:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_hicap.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_hicap_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass


# rule extract_kleborate_kpneumoniae_abaumanii:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_kleborate.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_kleborate_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#             report.to_csv(output[0], header=True, index=False)
#         except EmptyDataError as e:
#             os.system(f"touch {output[0]}")

# rule extract_legsta_lpneumophila:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_legsta.csv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_legsta_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0])
#         except EmptyDataError as e:
#             pass

# rule extract_lissero_lmonocytogenes:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_lissero.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_lissero_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass

# rule extract_lpgenomics_lpneumophila:
#     input:
#         out_path = config['output_directory']+"{sample_id_pattern}-predictResults.txt"
#     output:
#         config['output_directory']+'{sample_id_pattern}-predictResults_std.csv'
#     run:


# rule extract_meningotype_nmeningitidis:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_meningtotype.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_meningtotype_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass

# rule extract_bigsdb_lmonocytogenes:
#     input:
#         cgmlst = config['output_directory']+'{sample_id_pattern}_pasteur_cgmlst.json',
#         serogrp = config['output_directory']+'{sample_id_pattern}_pasteur_pcr_serogroup.json'
#     output:
#         config['output_directory']+'{sample_id_pattern}_pasteur_pcr_serogroup_std.csv'
#     run:


# rule extract_publmst_ngonorrhoe:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_ngmast.json'
#     output:
#         config['output_directory']+'{sample_id_pattern}_ngmast_std.csv'
#     run:


# rule extract_publmst_abaumanii:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_ab_pumblst.json'
#     output:
#         config['output_directory']+'{sample_id_pattern}_ab_pumblst_std.csv'
#     run:


# rule extract_sccmec_saureus:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_sccmec.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_sccmec_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass

# rule extract_seqsero_senterica:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_SeqSero.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_SeqSero_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass

# rule extract_sistr_senterica:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_sistr.csv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_sistr_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass

# rule extract_spatyper_saureus:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_spatyper.txt'
#     output:
#         config['output_directory']+'{sample_id_pattern}_spatyper_std.csv'
#     run:


# rule extract_ectyper_ecoli:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_ectyper.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_ectyper_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass

# rule extract_seroba_spneumoniae:
#     input:
#         out_path = config['output_directory']+'{sample_id_pattern}_seroba.tsv'
#     output:
#         config['output_directory']+'{sample_id_pattern}_seroba_std.csv'
#     run:
#         try:
#             report = pd.read_csv(input[0], sep="\t")
#         except EmptyDataError as e:
#             pass
