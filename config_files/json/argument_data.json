{
    "description": "This is a wrapper script of ARDETYPE (v.1.0) NGS data processing pipeline.\n\nIt is designed to perform species-agnostic and species-specific analysis paired-end (PE) bacterial Illumina reads.\nPipeline is structured in terms of modules. Each module corresponds to a Snakemake script (snakefile) and a python module object.\nSnakefiles are used to define data processing rules. Module class objects store information about inputs and expected outputs for these rules.\nThey also handle file placement operations, module configuration, information transfer between modules,\nand other processes that are not directly involved in running analysis on files. All modules use open-source software.\n\nModules:\n    bact_core - species-agnostic - covers basic QC of fastq files (fastp), filtering human host reads (kraken2),\n        running denovo assembly (shovill) and taxonomic classification of reads & contigs (kraken2).\n    bact_shell - species-agnostic - covers assembly QC (quast), resistance profiling (rgi-card; amr++v2.0, resfinder)\n        and attempting to reconstruct and type plasmids (mob-suite)\n    bact_tip - species-specific - covers species-dependent sub-typing methods.\n    bact_shape - reporting module used to summarize the results for each sample in a csv report table.\n\nThe safest option is to run the pipeline using -mode all argument, starting from raw fastq files (illumina format: _R[1,2]_001.fastq.gz).\nHowever, bact_core and bact_shell modules can be run separately, provided that required input files are present in input folder.\n(see config_file/json/module_data.json/module_name/patterns/inputs)",
    "required_arguments": [
        [
            "-m",
            "--mode",
            "Selecting mode that allows to run specific modules of the pipeline:\nall - run all modules (starting from fastq files)\ncore - run only bact_core module (starting from fastq files)\nshell - run only bact_shell module (starting from fasta & fastq file).\nlog_analysis - summarise logs of all jobs and update log_summary.html (no input required).\nmerge - move files from --merge_from one or many paths into --output_path, and run all modules to produce unified reports"
        ]
    ],
    "optional": {
        "arguments": [
            [
                "-i",
                "--input",
                "Path to directory that contains files to be analysed (files are NOT parsed from subfolders).\nCheck config_files/json/module_data/patterns/inputs section for expected input file extensions for each module)",
                null
            ],
            [
                "-c",
                "--config",
                "Path to the config file (if not supplied, the copy of the template config_modular.yaml will be used).",
                "./config_files/yaml/config_modular.yaml"
            ],
            [
                "-o",
                "--output_dir",
                "Path to the output directory where the results will be stored (ardetype_output/ by-default).",
                "ardetype_output/"
            ],
            [
                "-n",
                "--num_jobs",
                "Maximum number of jobs to be run in-parallel on different nodes of HPC (12 by-default).",
                12
            ],
            [
                "-r",
                "--retry_times",
                "Number of times the snakemake will try to reschedule failed jobs (3 by-default).",
                3
            ]
        ],
        "flags": [
            [
                "-s",
                "--install_snakemake",
                "Flag to install mamba and snakemake for the current HPC user, if it is not already installed."
            ],
            [
                "-j",
                "--submit_modules",
                "Flag to run modules as individual jobs on HPC (without submitting subjobs to computational nodes):\nsnakemake option flags (-t -f -g) do not apply to this run mode. Please modify ardetype_jobscript.sh to ensure desired behavior."
            ],
            [
                "-t",
                "--dry_run",
                "Flag to test-run all snakemake rules in all modules (-np option)."
            ],
            [
                "-f",
                "--force_all",
                "Flag to rerun all snakemake rules in all modules (--forceall option)."
            ],
            [
                "-g",
                "--rule_graph",
                "Flag to visualize snakemage job graphs for all modules and save as pdf file (--rulegraph option)."
            ],
            [
                "-p",
                "--pack_output",
                "Flag to combine output for each sample in separate folder, named after sample_id. \n If rerun is required after packing, run using --unpack_output flag."
            ],
            [
                "-u",
                "--unpack_output",
                "Flag to move packed output (see --pack_output flag) to specified output folder.\nSuggested use: if rerun is required after running with --pack_output flag, use this flag to move output files from subfolders (making them detectable by snakemake)."
            ],
            [
                "-l",
                "--clean_job_logs",
                "Flag to remove all job log files that are older than 30 days."
            ]
        ],
        "nargs": [
            [
                "-mf",
                "--merge_from",
                "Argument to supply paths to folders containing ardetype output that should be combined."
            ]
        ]
    }
}